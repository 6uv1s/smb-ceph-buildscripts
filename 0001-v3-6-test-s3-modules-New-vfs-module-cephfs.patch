From 36389b46e2406b0ffb79b455b3d3d7e3f41004e2 Mon Sep 17 00:00:00 2001
From: Sam Lang <sam.lang@inktank.com>
Date: Mon, 22 Oct 2012 08:51:56 -0500
Subject: [PATCH] v3-6-test: s3/modules: New vfs module: cephfs

Implements a vfs module for cephfs, a distributed file system
with posix semantics, built on the ceph distributed object
storage layer.  The ceph vfs module interfaces to the libcephfs
userspace API, and is primarily a lightweight wrapper around
libcephfs, translating error codes and parameters as necessary.

Signed-off-by: Sam Lang <sam.lang@inktank.com>
---
 source3/Makefile.in           |    5 +
 source3/configure.in          |   21 +
 source3/modules/vfs_ceph.c    | 1182 +++++++++++++++++++++++++++++++++++++++++
 source3/modules/wscript_build |   10 +
 source3/wscript               |    7 +
 5 files changed, 1225 insertions(+)
 create mode 100644 source3/modules/vfs_ceph.c

diff --git a/source3/Makefile.in b/source3/Makefile.in
index f4e8579..c50daae 100644
--- a/source3/Makefile.in
+++ b/source3/Makefile.in
@@ -846,6 +846,7 @@ VFS_SCANNEDONLY_OBJ = modules/vfs_scannedonly.o
 VFS_CROSSRENAME_OBJ = modules/vfs_crossrename.o
 VFS_LINUX_XFS_SGID_OBJ = modules/vfs_linux_xfs_sgid.o
 VFS_TIME_AUDIT_OBJ = modules/vfs_time_audit.o
+VFS_CEPH_OBJ = modules/vfs_ceph.o
 
 PAM_ERRORS_OBJ = ../libcli/auth/pam_errors.o
 PLAINTEXT_AUTH_OBJ = auth/pampass.o auth/pass_check.o $(PAM_ERRORS_OBJ)
@@ -3098,6 +3099,10 @@ bin/time_audit.@SHLIBEXT@: $(BINARY_PREREQS) $(VFS_TIME_AUDIT_OBJ)
 	@echo "Building plugin $@"
 	@$(SHLD_MODULE) $(VFS_TIME_AUDIT_OBJ)
 
+bin/ceph.@SHLIBEXT@: $(BINARY_PREREQS) $(VFS_CEPH_OBJ)
+	@echo "Building plugin $@"
+	@$(SHLD_MODULE) $(VFS_CEPH_OBJ)
+
 #########################################################
 ## IdMap NSS plugins
 
diff --git a/source3/configure.in b/source3/configure.in
index 014d844..0820de6 100644
--- a/source3/configure.in
+++ b/source3/configure.in
@@ -1186,6 +1186,26 @@ fi
 AC_SUBST(ONEFS_LIBS)
 LIBS="$save_LIBS"
 
+#############################
+# check if building with ceph 
+printf "%s" "checking for CephFS... "
+AC_CHECK_HEADERS(cephfs/libcephfs.h)
+save_LIBS="$LIBS"
+LIBS="$LIBS -lcephfs"
+AC_TRY_LINK([#include <cephfs/libcephfs.h>],
+	  [ceph_version(NULL, NULL, NULL)],
+	  samba_cv_HAVE_CEPHFS=yes,
+	  samba_cv_HAVE_CEPHFS=no)
+echo $samba_cv_HAVE_CEPHFS
+if test x"$ac_cv_header_cephfs_libcephfs_h" = x"yes" && test x"$samba_cv_HAVE_CEPHFS" = x"yes"; then
+    AC_DEFINE(HAVE_CEPH, 1, [Whether CEPH headers are available])
+    default_shared_modules="$default_shared_modules vfs_ceph"
+    CEPH_LIBS="-lcephfs"
+    save_LIBS="$save_LIBS -lcephfs"
+fi
+AC_SUBST(CEPH_LIBS)
+LIBS="$save_LIBS"
+
 # Note that all the libunwind symbols in the API are defined to internal
 # platform-specific version, so we must include libunwind.h before checking
 # any of them.
@@ -6958,6 +6978,7 @@ SMB_MODULE(vfs_scannedonly, \$(VFS_SCANNEDONLY_OBJ), "bin/scannedonly.$SHLIBEXT"
 SMB_MODULE(vfs_crossrename, \$(VFS_CROSSRENAME_OBJ), "bin/crossrename.$SHLIBEXT", VFS)
 SMB_MODULE(vfs_linux_xfs_sgid, \$(VFS_LINUX_XFS_SGID_OBJ), "bin/linux_xfs_sgid.$SHLIBEXT", VFS)
 SMB_MODULE(vfs_time_audit, \$(VFS_TIME_AUDIT_OBJ), "bin/time_audit.$SHLIBEXT", VFS)
+SMB_MODULE(vfs_ceph, \$(VFS_CEPH_OBJ), "bin/ceph.$SHLIBEXT", VFS)
 
 SMB_SUBSYSTEM(VFS,smbd/vfs.o)
 
diff --git a/source3/modules/vfs_ceph.c b/source3/modules/vfs_ceph.c
new file mode 100644
index 0000000..2acf032
--- /dev/null
+++ b/source3/modules/vfs_ceph.c
@@ -0,0 +1,1182 @@
+/*
+   Unix SMB/CIFS implementation.
+   Wrap disk only vfs functions to sidestep dodgy compilers.
+   Copyright (C) Tim Potter 1998
+   Copyright (C) Jeremy Allison 2007
+   Copyright (C) Brian Chrisman 2011 <bchrisman@gmail.com>
+   Copyright (C) Richard Sharpe 2011 <realrichardsharpe@gmail.com>
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3 of the License, or
+   (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program.  If not, see <http://www.gnu.org/licenses/>.
+*/
+
+/*
+ * This VFS only works with the libceph.so user-space client. It is not needed
+ * if you are using the kernel client or the FUSE client.
+ *
+ * Add the following smb.conf parameter to each share that will be hosted on
+ * Ceph:
+ *
+ *   vfs objects = ceph [any others you need go here]
+ */
+
+#include "includes.h"
+#include "smbd/smbd.h"
+#include <dirent.h>
+#include <sys/statvfs.h>
+#include "cephfs/libcephfs.h"
+#include "smbprofile.h"
+
+#undef DBGC_CLASS
+#define DBGC_CLASS DBGC_VFS
+
+/*
+ * Note, libceph's return code model is to return -errno! So we have to convert
+ * to what Samba expects, with is set errno to -return and return -1
+ */
+#define WRAP_RETURN(_res) \
+	if (_res < 0) { \
+		errno = -_res; \
+		return -1; \
+	} \
+	return _res \
+
+/*
+ * We mount only one file system and then all shares are assumed to be in that.
+ * FIXME: If we want to support more than one FS, then we have to deal with
+ * this differently.
+ *
+ * So, cmount tells us if we have been this way before and whether
+ * we need to mount ceph and cmount_cnt tells us how many times we have 
+ * connected
+ */
+static struct ceph_mount_info * cmount = NULL;
+static uint32_t cmount_cnt = 0;
+
+/* Check for NULL pointer parameters in cephwrap_* functions */
+
+/* We don't want to have NULL function pointers lying around.  Someone
+   is sure to try and execute them.  These stubs are used to prevent
+   this possibility. */
+
+static int cephwrap_connect(vfs_handle_struct *handle,  const char *service, const char *user)
+{
+	int ret;
+	char buf[256];
+
+	const char * conf_file;
+
+	if (cmount) {
+		handle->data = cmount; /* We have been here before */
+		cmount_cnt++;
+		return 0;
+	}
+
+	conf_file = lp_parm_const_string(SNUM(handle->conn), "ceph", "config_file", NULL);
+
+	DEBUG(2, ( "[CEPH] calling: ceph_create\n" ));
+	ret = ceph_create(&cmount, NULL);
+	if (ret)
+		goto err_out;
+
+	if (conf_file) {
+		/* Override the config file */
+		DEBUG(2, ( "[CEPH] calling: ceph_conf_read_file\n" ));
+		ret = ceph_conf_read_file(cmount, conf_file);
+	} else {
+
+		DEBUG(2, ( "[CEPH] calling: ceph_conf_read_file with %s\n", conf_file));
+		ret = ceph_conf_read_file(cmount, NULL);
+	}
+
+	if (ret)
+		goto err_out;
+
+	DEBUG(2, ( "[CEPH] calling: ceph_conf_get\n" ));
+	ret = ceph_conf_get(cmount, "log file", buf, sizeof(buf));
+	if (ret < 0)
+		goto err_out;
+
+	DEBUG(2, ("[CEPH] calling: ceph_mount\n"));
+	ret = ceph_mount(cmount, NULL);
+	if (ret < 0)
+		goto err_out;
+
+
+	/*
+	 * encode mount context/state into our vfs/connection holding structure
+	 * cmount is a ceph_mount_t* 
+	 */
+	handle->data = cmount;
+	cmount_cnt++;
+
+	return 0;
+
+err_out:
+	/*
+	 * Handle the error correctly. Ceph returns -errno.
+	 */
+	DEBUG(2, ("[CEPH] Error return: %s\n", strerror(-ret)));
+	WRAP_RETURN(ret);
+}
+
+static void cephwrap_disconnect(vfs_handle_struct *handle)
+{
+	if (!cmount) {
+		DEBUG(0, ("[CEPH] Error, ceph not mounted\n"));
+		return;
+	}
+
+	/* Should we unmount/shutdown? Only if the last disconnect? */
+	if (--cmount_cnt) {
+		DEBUG(10, ("[CEPH] Not shuting down CEPH because still more connections\n"));
+		return;
+	}
+
+	ceph_shutdown(cmount);
+
+	cmount = NULL;  /* Make it safe */
+}
+
+/* Disk operations */
+
+static uint64_t cephwrap_disk_free(vfs_handle_struct *handle,  const char *path, bool small_query, uint64_t *bsize,
+			       uint64_t *dfree, uint64_t *dsize)
+{
+	struct statvfs statvfs_buf;	
+	int ret;
+
+	if (!(ret = ceph_statfs(handle->data, path, &statvfs_buf))) {
+		/*
+		 * Provide all the correct values.
+		 */
+		*bsize = statvfs_buf.f_bsize;
+		*dfree = statvfs_buf.f_bsize * statvfs_buf.f_bavail;
+		*dsize = statvfs_buf.f_bsize * statvfs_buf.f_blocks;
+		DEBUG(10, ("[CEPH] bsize: %lu, dfree: %lu, dsize: %lu\n",
+			*bsize, *dfree, *dsize));
+		return *dfree;
+	} else {
+		DEBUG(10, ("[CEPH] ceph_statfs returned %d\n", ret));
+		WRAP_RETURN(ret);
+	}
+}
+
+static int cephwrap_get_quota(struct vfs_handle_struct *handle,  enum SMB_QUOTA_TYPE qtype, unid_t id, SMB_DISK_QUOTA *qt)
+{
+	/* libceph: Ceph does not implement this */
+#if 0
+/* was ifdef HAVE_SYS_QUOTAS */
+	int ret;
+
+	ret = ceph_get_quota(handle->conn->connectpath, qtype, id, qt);
+
+	if (ret) {
+		errno = -ret;
+		ret = -1;
+	}
+
+	return ret;
+#else
+	errno = ENOSYS;
+	return -1;
+#endif
+}
+
+static int cephwrap_set_quota(struct vfs_handle_struct *handle,  enum SMB_QUOTA_TYPE qtype, unid_t id, SMB_DISK_QUOTA *qt)
+{
+	/* libceph: Ceph does not implement this */
+#if 0
+/* was ifdef HAVE_SYS_QUOTAS */
+	int ret;
+
+	ret = ceph_set_quota(handle->conn->connectpath, qtype, id, qt);
+	if (ret) {
+		errno = -ret;
+		ret = -1;
+	}
+
+	return ret;
+#else
+	WRAP_RETURN(-ENOSYS);
+#endif
+}
+
+static int cephwrap_statvfs(struct vfs_handle_struct *handle,  const char *path, vfs_statvfs_struct *statbuf)
+{
+	struct statvfs statvfs_buf;	
+	int ret;
+
+	ret = ceph_statfs(handle->data, path, &statvfs_buf);
+	if (ret < 0) {
+		WRAP_RETURN(ret);
+	} else {
+		statbuf->OptimalTransferSize = statvfs_buf.f_frsize;
+		statbuf->BlockSize = statvfs_buf.f_bsize;
+		statbuf->TotalBlocks = statvfs_buf.f_blocks;
+		statbuf->BlocksAvail = statvfs_buf.f_bfree;
+		statbuf->UserBlocksAvail = statvfs_buf.f_bavail;
+		statbuf->TotalFileNodes = statvfs_buf.f_files;
+		statbuf->FreeFileNodes = statvfs_buf.f_ffree;
+		statbuf->FsIdentifier = statvfs_buf.f_fsid;
+		DEBUG(10, ("[CEPH] f_bsize: %ld, f_blocks: %ld, f_bfree: %ld, f_bavail: %ld\n",
+			statvfs_buf.f_bsize, statvfs_buf.f_blocks, 
+			statvfs_buf.f_bfree, statvfs_buf.f_bavail));
+	}
+	return ret;
+}
+
+/* Directory operations */
+
+static DIR *cephwrap_opendir(struct vfs_handle_struct *handle,  const char *fname, const char *mask, uint32 attr)
+{
+	int ret = 0;
+	struct ceph_dir_result *result;
+	DEBUG(10, ("[CEPH] name: %s\n", fname));
+
+	/* Returns NULL if it does not exist or there are problems ? */
+	ret = ceph_opendir(handle->data, fname, &result);
+	if (ret < 0) {
+		result = NULL;
+		errno = -ret; /* We return result which is NULL in this case */
+	}
+
+	return (DIR *) result;
+}
+
+static SMB_STRUCT_DIRENT *cephwrap_readdir(vfs_handle_struct *handle,
+				           SMB_STRUCT_DIR *dirp,
+				           SMB_STRUCT_STAT *sbuf)
+{
+	struct dirent *result;
+
+	result = ceph_readdir(handle->data, (struct ceph_dir_result *) dirp);
+	DEBUG(10, ("[CEPH] result: %p\n", result));
+
+	/* Default Posix readdir() does not give us stat info.
+	 * Set to invalid to indicate we didn't return this info. */
+	if (sbuf)
+		SET_STAT_INVALID(*sbuf);
+	return (SMB_STRUCT_DIRENT *) result;
+}
+
+static void cephwrap_seekdir(vfs_handle_struct *handle, DIR *dirp, long offset)
+{
+	ceph_seekdir(handle->data, (struct ceph_dir_result *) dirp, offset);
+}
+
+static long cephwrap_telldir(vfs_handle_struct *handle, DIR *dirp)
+{
+	long ret;
+	ret = ceph_telldir(handle->data, (struct ceph_dir_result *) dirp);
+	if (ret < 0) {
+		errno = -ret;
+		ret = -1;
+	}
+	DEBUG(10, ("[CEPH] ret: %ld, errno: %d\n", ret, errno));
+	return ret;
+}
+
+static void cephwrap_rewinddir(vfs_handle_struct *handle, DIR *dirp)
+{
+	ceph_rewinddir(handle->data, (struct ceph_dir_result *) dirp);
+}
+
+static int cephwrap_mkdir(vfs_handle_struct *handle,  const char *path, mode_t mode)
+{
+	int result;
+	bool has_dacl = False;
+	char *parent = NULL;
+
+
+	if (lp_inherit_acls(SNUM(handle->conn))
+	    && parent_dirname(talloc_tos(), path, &parent, NULL)
+	    && (has_dacl = directory_has_default_acl(handle->conn, parent)))
+		mode = 0777;
+
+	TALLOC_FREE(parent);
+
+	result = ceph_mkdir(handle->data, path, mode);
+
+	/*
+	 * Note. This order is important
+	 */
+	if (result) {
+		WRAP_RETURN(result);
+	} else if (result == 0 && !has_dacl) {
+		/*
+		 * We need to do this as the default behavior of POSIX ACLs
+		 * is to set the mask to be the requested group permission
+		 * bits, not the group permission bits to be the requested
+		 * group permission bits. This is not what we want, as it will
+		 * mess up any inherited ACL bits that were set. JRA.
+		 */
+		int saved_errno = errno; /* We may get ENOSYS */
+		if ((SMB_VFS_CHMOD_ACL(handle->conn, path, mode) == -1) && (errno == ENOSYS))
+			errno = saved_errno;
+	}
+
+	return result;
+}
+
+static int cephwrap_rmdir(vfs_handle_struct *handle,  const char *path)
+{
+	int result;
+
+	result = ceph_rmdir(handle->data, path);
+	WRAP_RETURN(result);
+}
+
+static int cephwrap_closedir(vfs_handle_struct *handle, DIR *dirp)
+{
+	int result;
+
+	result = ceph_closedir(handle->data, (struct ceph_dir_result *) dirp);
+	WRAP_RETURN(result);
+}
+
+/* File operations */
+
+static int cephwrap_open(vfs_handle_struct *handle,
+			struct smb_filename *smb_fname,
+			files_struct *fsp, int flags, mode_t mode)
+{
+	int result = -ENOENT;
+	DEBUG(10, ("[CEPH] name: %s\n", smb_fname_str_dbg(smb_fname)));
+
+	if (smb_fname->stream_name) {
+		goto out;
+	}
+
+	result = ceph_open(handle->data, smb_fname->base_name, flags, mode);
+out:
+	WRAP_RETURN(result);
+}
+
+static int cephwrap_close(vfs_handle_struct *handle, files_struct *fsp)
+{
+	int result;
+
+	result = ceph_close(handle->data, fsp->fh->fd);
+	if (result) {
+		errno = -result;
+		result = -1;
+	}
+	return result;
+}
+
+static ssize_t cephwrap_read(vfs_handle_struct *handle, files_struct *fsp, void *data, size_t n)
+{
+	ssize_t result;
+
+	/* Using -1 for the offset means read/write rather than pread/pwrite */
+	result = ceph_read(handle->data, fsp->fh->fd, data, n, -1);
+	if (result < 0) {
+		errno = -result;
+		result = -1;
+	}
+	return result;
+}
+
+static ssize_t cephwrap_pread(vfs_handle_struct *handle, files_struct *fsp, void *data,
+			size_t n, off_t offset)
+{
+	ssize_t result;
+
+	result = ceph_read(handle->data, fsp->fh->fd, data, n, offset);
+	WRAP_RETURN(result);
+}
+
+
+static ssize_t cephwrap_write(vfs_handle_struct *handle, files_struct *fsp, const void *data, size_t n)
+{
+	ssize_t result;
+
+	result = ceph_write(handle->data, fsp->fh->fd, data, n, -1);
+
+	if (result < 0) {
+		WRAP_RETURN(result);
+	}
+	fsp->fh->pos += result;
+	return result;
+}
+
+static ssize_t cephwrap_pwrite(vfs_handle_struct *handle, files_struct *fsp, const void *data,
+			size_t n, off_t offset)
+{
+	ssize_t result;
+
+	result = ceph_write(handle->data, fsp->fh->fd, data, n, offset);
+	WRAP_RETURN(result);
+}
+
+static off_t cephwrap_lseek(vfs_handle_struct *handle, files_struct *fsp, off_t offset, int whence)
+{
+	off_t result = 0;
+
+	/* Cope with 'stat' file opens. */
+	if (fsp->fh->fd != -1) {
+		result = ceph_lseek(handle->data, fsp->fh->fd, offset, whence);
+		WRAP_RETURN(result);
+	}
+	return result;
+}
+
+static ssize_t cephwrap_sendfile(vfs_handle_struct *handle, int tofd, files_struct *fromfsp, const DATA_BLOB *hdr,
+			off_t offset, size_t n)
+{
+	/*
+	 * We cannot support sendfile because libceph is in user space.
+	 */
+	errno = ENOTSUP;
+	return -1;
+}
+
+static ssize_t cephwrap_recvfile(vfs_handle_struct *handle,
+			int fromfd,
+			files_struct *tofsp,
+			off_t offset,
+			size_t n)
+{
+	/*
+	 * We cannot support recvfile because libceph is in user space.
+	 */
+	errno=ENOTSUP;
+	return -1;
+}
+
+static int cephwrap_rename(vfs_handle_struct *handle,
+			  const struct smb_filename *smb_fname_src,
+			  const struct smb_filename *smb_fname_dst)
+{
+	int result = -1;
+	if (smb_fname_src->stream_name || smb_fname_dst->stream_name) {
+		errno = ENOENT;
+		return result;
+	}
+
+	result = ceph_rename(handle->data, smb_fname_src->base_name, smb_fname_dst->base_name);
+	WRAP_RETURN(result);
+}
+
+static int cephwrap_fsync(vfs_handle_struct *handle, files_struct *fsp)
+{
+	int result;
+	result = ceph_fsync(handle->data, fsp->fh->fd, false);
+	WRAP_RETURN(result);
+}
+
+static void init_stat_ex_from_stat(struct stat_ex *dst, const struct stat *src)
+{
+	ZERO_STRUCT(*dst);
+
+	dst->st_ex_dev = src->st_dev;
+	dst->st_ex_ino = src->st_ino;
+	dst->st_ex_mode = src->st_mode;
+	dst->st_ex_nlink = src->st_nlink;
+	dst->st_ex_uid = src->st_uid;
+	dst->st_ex_gid = src->st_gid;
+	dst->st_ex_rdev = src->st_rdev;
+	dst->st_ex_size = src->st_size;
+	dst->st_ex_atime.tv_sec = src->st_atime;
+	dst->st_ex_mtime.tv_sec = src->st_mtime;
+	dst->st_ex_ctime.tv_sec = src->st_ctime;
+	dst->st_ex_btime.tv_sec = src->st_mtime;
+	dst->st_ex_blksize = src->st_blksize;
+	dst->st_ex_blocks = src->st_blocks;
+}
+
+static int cephwrap_stat(vfs_handle_struct *handle,
+			struct smb_filename *smb_fname)
+{
+	int result = -1;
+	struct stat stbuf;
+
+	DEBUG(10, ("[CEPH] name = %s\n", smb_fname_str_dbg(smb_fname)));
+
+	if (smb_fname->stream_name) {
+		errno = ENOENT;
+		return result;
+	}
+
+	result = ceph_stat(handle->data, smb_fname->base_name, (struct stat *) &stbuf);
+	if (result < 0) {
+		WRAP_RETURN(result);
+	}
+	init_stat_ex_from_stat(&(smb_fname->st), &stbuf);
+	return result;
+}
+
+static int cephwrap_fstat(vfs_handle_struct *handle, files_struct *fsp, SMB_STRUCT_STAT *sbuf)
+{
+	int result = -1;
+	struct stat stbuf;
+
+	result = ceph_fstat(handle->data, fsp->fh->fd, (struct stat *) &stbuf);
+	if (result < 0) {
+		WRAP_RETURN(result);
+	}
+	init_stat_ex_from_stat(sbuf, &stbuf);
+	return result;
+}
+
+static int cephwrap_lstat(vfs_handle_struct *handle,
+			 struct smb_filename *smb_fname)
+{
+	int result = -1;
+	struct stat stbuf;
+
+	DEBUG(10, ("[CEPH] name = %s\n", smb_fname_str_dbg(smb_fname)));
+
+	if (smb_fname->stream_name) {
+		errno = ENOENT;
+		return result;
+	}
+
+	result = ceph_lstat(handle->data, smb_fname->base_name, &stbuf);
+	if (result < 0) {
+		WRAP_RETURN(result);
+	}
+	init_stat_ex_from_stat(&(smb_fname->st), &stbuf);
+	DEBUG(10, ("[CEPH] result: %d, errno: %d\n", result, errno));
+	return result;
+}
+
+static int cephwrap_unlink(vfs_handle_struct *handle,
+			  const struct smb_filename *smb_fname)
+{
+	int result = -1;
+
+	if (smb_fname->stream_name) {
+		errno = ENOENT;
+		return result;
+	}
+	result = ceph_unlink(handle->data, smb_fname->base_name);
+	if (result) {
+		WRAP_RETURN(result);
+	}
+	return result;
+}
+
+static int cephwrap_chmod(vfs_handle_struct *handle,  const char *path, mode_t mode)
+{
+	int result;
+
+
+	/*
+	 * We need to do this due to the fact that the default POSIX ACL
+	 * chmod modifies the ACL *mask* for the group owner, not the
+	 * group owner bits directly. JRA.
+	 */
+
+
+	{
+		int saved_errno = errno; /* We might get ENOSYS */
+		if ((result = SMB_VFS_CHMOD_ACL(handle->conn, path, mode)) == 0) {
+			return result;
+		}
+		/* Error - return the old errno. */
+		errno = saved_errno;
+	}
+
+	result = ceph_chmod(handle->data, path, mode);
+	WRAP_RETURN(result);
+}
+
+static int cephwrap_fchmod(vfs_handle_struct *handle, files_struct *fsp, mode_t mode)
+{
+	int result;
+
+
+	/*
+	 * We need to do this due to the fact that the default POSIX ACL
+	 * chmod modifies the ACL *mask* for the group owner, not the
+	 * group owner bits directly. JRA.
+	 */
+
+	{
+		int saved_errno = errno; /* We might get ENOSYS */
+		if ((result = SMB_VFS_FCHMOD_ACL(fsp, mode)) == 0) {
+			return result;
+		}
+		/* Error - return the old errno. */
+		errno = saved_errno;
+	}
+
+#if defined(HAVE_FCHMOD)
+	result = ceph_fchmod(handle->data, fsp->fh->fd, mode);
+	WRAP_RETURN(result);
+#else
+	errno = ENOSYS;
+#endif
+	return -1;
+}
+
+static int cephwrap_chown(vfs_handle_struct *handle, const char *path, uid_t uid, gid_t gid)
+{
+	int result;
+	result = ceph_chown(handle->data, path, uid, gid);
+	WRAP_RETURN(result);
+}
+
+static int cephwrap_fchown(vfs_handle_struct *handle, files_struct *fsp, uid_t uid, gid_t gid)
+{
+	int result;
+#ifdef HAVE_FCHOWN
+
+	result = ceph_fchown(handle->data, fsp->fh->fd, uid, gid);
+	WRAP_RETURN(result);
+#else
+	errno = ENOSYS;
+	result = -1;
+#endif
+	return result;
+}
+
+static int cephwrap_lchown(vfs_handle_struct *handle, const char *path, uid_t uid, gid_t gid)
+{
+	int result;
+
+	result = ceph_lchown(handle->data, path, uid, gid);
+	WRAP_RETURN(result);
+}
+
+static int cephwrap_chdir(vfs_handle_struct *handle,  const char *path)
+{
+	int result = -1;
+	/*
+	 * If the path is just / use chdir because Ceph is below / and
+	 * cannot deal with changing directory above its mount point
+	 */
+	if (path && !strcmp(path, "/"))
+		return chdir(path);
+ 
+	result = ceph_chdir(handle->data, path);
+	WRAP_RETURN(result);
+}
+
+static char *cephwrap_getwd(vfs_handle_struct *handle, char *buf)
+{
+	const char *result;
+
+	if (!buf) {
+		errno = EINVAL;
+		return NULL;
+	}
+	result = ceph_getcwd(handle->data);
+	if (result) {
+		if (strlen(result) > PATH_MAX - 1) {
+			errno = ENAMETOOLONG;
+			return NULL;
+		} else {
+			strncpy(buf, result, PATH_MAX);
+			return buf;
+		}
+	} else {
+		return NULL;
+	}
+}
+
+static int strict_allocate_ftruncate(vfs_handle_struct *handle, files_struct *fsp, off_t len)
+{
+	off_t space_to_write;
+	uint64_t space_avail;
+	uint64_t bsize,dfree,dsize;
+	int ret;
+	NTSTATUS status;
+	SMB_STRUCT_STAT *pst;
+
+	status = vfs_stat_fsp(fsp);
+	if (!NT_STATUS_IS_OK(status)) {
+		return -1;
+	}
+	pst = &fsp->fsp_name->st;
+
+#ifdef S_ISFIFO
+	if (S_ISFIFO(pst->st_ex_mode))
+		return 0;
+#endif
+
+	if (pst->st_ex_size == len)
+		return 0;
+
+	/* Shrink - just ftruncate. */
+	if (pst->st_ex_size > len)
+		return ftruncate(fsp->fh->fd, len);
+
+	space_to_write = len - pst->st_ex_size;
+
+	/* for allocation try fallocate first. This can fail on some
+	   platforms e.g. when the filesystem doesn't support it and no
+	   emulation is being done by the libc (like on AIX with JFS1). In that
+	   case we do our own emulation. fallocate implementations can
+	   return ENOTSUP or EINVAL in cases like that. */
+	ret = SMB_VFS_FALLOCATE(fsp, VFS_FALLOCATE_EXTEND_SIZE,
+				pst->st_ex_size, space_to_write);
+	if (ret == ENOSPC) {
+		errno = ENOSPC;
+		return -1;
+	}
+	if (ret == 0) {
+		return 0;
+	}
+	DEBUG(10,("[CEPH] strict_allocate_ftruncate: SMB_VFS_FALLOCATE failed with "
+		"error %d. Falling back to slow manual allocation\n", ret));
+
+	/* available disk space is enough or not? */
+	space_avail = get_dfree_info(fsp->conn,
+				     fsp->fsp_name->base_name, false,
+				     &bsize,&dfree,&dsize);
+	/* space_avail is 1k blocks */
+	if (space_avail == (uint64_t)-1 ||
+			((uint64_t)space_to_write/1024 > space_avail) ) {
+		errno = ENOSPC;
+		return -1;
+	}
+
+	/* Write out the real space on disk. */
+	ret = vfs_slow_fallocate(fsp, pst->st_ex_size, space_to_write);
+	if (ret != 0) {
+		errno = ret;
+		ret = -1;
+	}
+
+	return 0;
+}
+
+static int cephwrap_ftruncate(vfs_handle_struct *handle, files_struct *fsp, off_t len)
+{
+	int result = -1;
+	SMB_STRUCT_STAT st;
+	char c = 0;
+	off_t currpos;
+
+
+	if (lp_strict_allocate(SNUM(fsp->conn))) {
+		result = strict_allocate_ftruncate(handle, fsp, len);
+		return result;
+	}
+
+	/* we used to just check HAVE_FTRUNCATE_EXTEND and only use
+	   sys_ftruncate if the system supports it. Then I discovered that
+	   you can have some filesystems that support ftruncate
+	   expansion and some that don't! On Linux fat can't do
+	   ftruncate extend but ext2 can. */
+
+	result = ceph_ftruncate(handle->data, fsp->fh->fd, len);
+	if (result == 0)
+		goto done;
+
+	/* According to W. R. Stevens advanced UNIX prog. Pure 4.3 BSD cannot
+	   extend a file with ftruncate. Provide alternate implementation
+	   for this */
+	currpos = SMB_VFS_LSEEK(fsp, 0, SEEK_CUR);
+	if (currpos == -1) {
+		goto done;
+	}
+
+	/* Do an fstat to see if the file is longer than the requested
+	   size in which case the ftruncate above should have
+	   succeeded or shorter, in which case seek to len - 1 and
+	   write 1 byte of zero */
+	if (SMB_VFS_FSTAT(fsp, &st) == -1) {
+		goto done;
+	}
+
+#ifdef S_ISFIFO
+	if (S_ISFIFO(st.st_ex_mode)) {
+		result = 0;
+		goto done;
+	}
+#endif
+
+	if (st.st_ex_size == len) {
+		result = 0;
+		goto done;
+	}
+
+	if (st.st_ex_size > len) {
+		/* the sys_ftruncate should have worked */
+		goto done;
+	}
+
+	if (SMB_VFS_LSEEK(fsp, len-1, SEEK_SET) != len -1)
+		goto done;
+
+	if (SMB_VFS_WRITE(fsp, &c, 1)!=1)
+		goto done;
+
+	/* Seek to where we were */
+	if (SMB_VFS_LSEEK(fsp, currpos, SEEK_SET) != currpos)
+		goto done;
+	result = 0;
+
+  done:
+
+	return result;
+}
+
+static bool cephwrap_lock(vfs_handle_struct *handle, files_struct *fsp, int op, off_t offset, off_t count, int type)
+{
+	return true;
+}
+
+static int cephwrap_kernel_flock(vfs_handle_struct *handle, files_struct *fsp,
+				uint32 share_mode, uint32 access_mask)
+{
+	/*
+	 * We must return zero here and pretend all is good.
+	 * One day we might have this in CEPH.
+	 */
+	return 0;
+}
+
+static bool cephwrap_getlock(vfs_handle_struct *handle, files_struct *fsp, off_t *poffset, off_t *pcount, int *ptype, pid_t *ppid)
+{
+	DEBUG(10, ("[CEPH] returning false and errno=0\n"));
+
+	errno = 0;
+
+	return false;
+}
+
+/*
+ * We cannot let this fall through to the default, because the file might only
+ * be accessible from libceph (which is a user-space client) but the fd might
+ * be for some file the kernel knows about.
+ */
+static int cephwrap_linux_setlease(vfs_handle_struct *handle, files_struct *fsp,
+				int leasetype)
+{
+	int result = -1;
+
+	errno = ENOSYS;
+	return result;
+}
+
+static int cephwrap_symlink(vfs_handle_struct *handle,  const char *oldpath, const char *newpath)
+{
+	int result = -1;
+	result = ceph_symlink(handle->data, oldpath, newpath);
+	if (result) {
+		errno = -result;
+		result = -1;
+	}
+
+	return result;
+}
+
+static int cephwrap_readlink(vfs_handle_struct *handle,  const char *path, char *buf, size_t bufsiz)
+{
+	int result = -1;
+	result = ceph_readlink(handle->data, path, buf, bufsiz);
+	if (result) {
+		errno = -result;
+		result = -1;
+	}
+
+	return result;
+}
+
+static int cephwrap_link(vfs_handle_struct *handle,  const char *oldpath, const char *newpath)
+{
+	int result = -1;
+	result = ceph_link(handle->data, oldpath, newpath);
+	if (result) {
+		errno = -result;
+		result = -1;
+	}
+
+	return result;
+}
+
+static int cephwrap_mknod(vfs_handle_struct *handle,  const char *pathname, mode_t mode, SMB_DEV_T dev)
+{
+	int result = -1;
+	result = ceph_mknod(handle->data, pathname, mode, dev);
+	if (result) {
+		errno = -result;
+		result = -1;
+	}
+
+	return result;
+}
+
+/*
+ * This is a simple version of real-path ... a better version is needed to
+ * ask libceph about symbolic links.
+ */
+static char *cephwrap_realpath(vfs_handle_struct *handle,  const char *path)
+{
+	char *result;
+	size_t len = strlen(path);
+
+	result = SMB_MALLOC_ARRAY(char, PATH_MAX+1);
+	if (len && (path[0] == '/')) {
+		int r = asprintf(&result, "%s", path);
+		if (r < 0) return NULL;
+	} else if ((len >= 2) && (path[0] == '.') && (path[1] == '/')) {
+		if (len == 2) {
+			int r = asprintf(&result, "%s", 
+					handle->conn->connectpath);
+			if (r < 0) return NULL;
+		} else {
+			int r = asprintf(&result, "%s/%s",
+					handle->conn->connectpath, &path[2]);
+			if (r < 0) return NULL;
+		}
+	} else {
+		int r = asprintf(&result, "%s/%s",
+				handle->conn->connectpath, path);
+		if (r < 0) return NULL;
+	}
+	return result;
+}
+
+static NTSTATUS cephwrap_notify_watch(vfs_handle_struct *vfs_handle,
+				     struct sys_notify_context *ctx,
+				     struct notify_entry *e,
+				     void (*callback)(struct sys_notify_context *ctx, 
+						      void *private_data,
+						      struct notify_event *ev),
+				     void *private_data,
+				     void *handle_p)
+{
+	/*
+	 * We cannot call inotify on files the kernel does not know about
+	 */
+	return NT_STATUS_OK;
+}
+
+static int cephwrap_chflags(vfs_handle_struct *handle, const char *path,
+			   unsigned int flags)
+{
+	errno = ENOSYS;
+	return -1;
+}
+
+static int cephwrap_get_real_filename(struct vfs_handle_struct *handle,
+				     const char *path,
+				     const char *name,
+				     TALLOC_CTX *mem_ctx,
+				     char **found_name)
+{
+	/*
+	 * Don't fall back to get_real_filename so callers can differentiate
+	 * between a full directory scan and an actual case-insensitive stat.
+	 */
+	errno = EOPNOTSUPP;
+	return -1;
+}
+
+static const char *cephwrap_connectpath(struct vfs_handle_struct *handle,
+				       const char *fname)
+{
+	return handle->conn->connectpath;
+}
+
+/****************************************************************
+ Extended attribute operations.
+*****************************************************************/
+
+static ssize_t cephwrap_getxattr(struct vfs_handle_struct *handle,const char *path, const char *name, void *value, size_t size)
+{
+	DEBUG(10, ("[CEPH] path: %s, name: %s\n", path, name));
+	int ret = ceph_getxattr(handle->data, path, name, value, size);
+	if (ret < 0) {
+		WRAP_RETURN(ret);
+	} else {
+		return (ssize_t)ret;
+	}
+}
+
+static ssize_t cephwrap_fgetxattr(struct vfs_handle_struct *handle, struct files_struct *fsp, const char *name, void *value, size_t size)
+{
+	DEBUG(10, ("[CEPH] path: %s, name: %s\n", fsp->fsp_name->base_name, name));
+	int ret = ceph_getxattr(handle->data, fsp->fsp_name->base_name, name, value, size);
+	if (ret < 0) {
+		WRAP_RETURN(ret);
+	} else {
+		return (ssize_t)ret;
+	}
+}
+
+static ssize_t cephwrap_listxattr(struct vfs_handle_struct *handle, const char *path, char *list, size_t size)
+{
+	int ret = ceph_listxattr(handle->data, path, list, size);
+	if (ret < 0) {
+		WRAP_RETURN(ret);
+	} else {
+		return (ssize_t)ret;
+	}
+}
+
+static ssize_t cephwrap_llistxattr(struct vfs_handle_struct *handle, const char *path, char *list, size_t size)
+{
+	int ret = ceph_llistxattr(handle->data, path, list, size);
+	if (ret < 0) {
+		WRAP_RETURN(ret);
+	} else {
+		return (ssize_t)ret;
+	}
+}
+
+static ssize_t cephwrap_flistxattr(struct vfs_handle_struct *handle, struct files_struct *fsp, char *list, size_t size)
+{
+	int ret = ceph_listxattr(handle->data, fsp->fsp_name->base_name, list, size);
+	if (ret < 0) {
+		WRAP_RETURN(ret);
+	} else {
+		return (ssize_t)ret;
+	}
+}
+
+static int cephwrap_removexattr(struct vfs_handle_struct *handle, const char *path, const char *name)
+{
+	DEBUG(10, ("[CEPH] path: %s, name: %s\n", path, name));
+	int ret = ceph_removexattr(handle->data, path, name);
+	WRAP_RETURN(ret);
+}
+
+static int cephwrap_fremovexattr(struct vfs_handle_struct *handle, struct files_struct *fsp, const char *name)
+{
+	DEBUG(10, ("[CEPH] path: %s, name: %s\n", fsp->fsp_name->base_name, name));
+	int ret = ceph_removexattr(handle->data, fsp->fsp_name->base_name, name);
+	WRAP_RETURN(ret);
+}
+
+static int cephwrap_setxattr(struct vfs_handle_struct *handle, const char *path, const char *name, const void *value, size_t size, int flags)
+{
+	DEBUG(10, ("[CEPH] path: %s, name: %s\n", path, name));
+	int ret = ceph_setxattr(handle->data, path, name, value, size, flags);
+	WRAP_RETURN(ret);
+}
+
+static int cephwrap_fsetxattr(struct vfs_handle_struct *handle, struct files_struct *fsp, const char *name, const void *value, size_t size, int flags)
+{
+	DEBUG(10, ("[CEPH] path: %s, name: %s\n", fsp->fsp_name->base_name, name));
+	int ret = ceph_setxattr(handle->data, fsp->fsp_name->base_name, name, value, size, flags);
+	WRAP_RETURN(ret);
+}
+
+static bool cephwrap_aio_force(struct vfs_handle_struct *handle, struct files_struct *fsp)
+{
+
+	/*
+	 * We do not support AIO yet.
+	 */
+
+	errno = ENOTSUP;
+	return -1;
+}
+
+static bool cephwrap_is_offline(struct vfs_handle_struct *handle, 
+				const struct smb_filename *fname, 
+				SMB_STRUCT_STAT *sbuf)
+{
+	return false;
+}
+
+static int cephwrap_set_offline(struct vfs_handle_struct *handle,
+				const struct smb_filename *fname)
+{
+	errno = ENOTSUP;
+	return -1;
+}
+
+static struct vfs_fn_pointers ceph_fns = {
+	/* Disk operations */
+
+	.connect_fn = cephwrap_connect,
+	.disconnect = cephwrap_disconnect,
+	.disk_free = cephwrap_disk_free,
+	.get_quota = cephwrap_get_quota,
+	.set_quota = cephwrap_set_quota,
+	.statvfs = cephwrap_statvfs,
+
+	/* Directory operations */
+
+	.opendir = cephwrap_opendir,
+	.readdir = cephwrap_readdir,
+	.seekdir = cephwrap_seekdir,
+	.telldir = cephwrap_telldir,
+	.rewind_dir = cephwrap_rewinddir,
+	.mkdir = cephwrap_mkdir,
+	.rmdir = cephwrap_rmdir,
+	.closedir = cephwrap_closedir,
+
+	/* File operations */
+
+	.open_fn = cephwrap_open,
+	.close_fn = cephwrap_close,
+	.vfs_read = cephwrap_read,
+	.pread = cephwrap_pread,
+	.write = cephwrap_write,
+	.pwrite = cephwrap_pwrite,
+	.lseek = cephwrap_lseek,
+	.sendfile = cephwrap_sendfile,
+	.recvfile = cephwrap_recvfile,
+	.rename = cephwrap_rename,
+	.fsync = cephwrap_fsync,
+	.stat = cephwrap_stat,
+	.fstat = cephwrap_fstat,
+	.lstat = cephwrap_lstat,
+	.unlink = cephwrap_unlink,
+	.chmod = cephwrap_chmod,
+	.fchmod = cephwrap_fchmod,
+	.chown = cephwrap_chown,
+	.fchown = cephwrap_fchown,
+	.lchown = cephwrap_lchown,
+	.chdir = cephwrap_chdir,
+	.getwd = cephwrap_getwd,
+	.ftruncate = cephwrap_ftruncate,
+	.lock = cephwrap_lock,
+	.kernel_flock = cephwrap_kernel_flock,
+	.linux_setlease = cephwrap_linux_setlease,
+	.getlock = cephwrap_getlock,
+	.symlink = cephwrap_symlink,
+	.vfs_readlink = cephwrap_readlink,
+	.link = cephwrap_link,
+	.mknod = cephwrap_mknod,
+	.realpath = cephwrap_realpath,
+	.notify_watch = cephwrap_notify_watch,
+	.chflags = cephwrap_chflags,
+	.get_real_filename = cephwrap_get_real_filename,
+	.connectpath = cephwrap_connectpath,
+
+	/* EA operations. */
+	.getxattr = cephwrap_getxattr,
+	.fgetxattr = cephwrap_fgetxattr,
+	.listxattr = cephwrap_listxattr,
+	.llistxattr = cephwrap_llistxattr,
+	.flistxattr = cephwrap_flistxattr,
+	.removexattr = cephwrap_removexattr,
+	.fremovexattr = cephwrap_fremovexattr,
+	.setxattr = cephwrap_setxattr,
+	.fsetxattr = cephwrap_fsetxattr,
+
+	/* aio operations */
+	.aio_force = cephwrap_aio_force,
+
+	/* offline operations */
+	.is_offline = cephwrap_is_offline,
+	.set_offline = cephwrap_set_offline
+};
+
+NTSTATUS vfs_ceph_init(void);
+NTSTATUS vfs_ceph_init(void)
+{
+	return smb_register_vfs(SMB_VFS_INTERFACE_VERSION,
+				"ceph", &ceph_fns);
+}
+
diff --git a/source3/modules/wscript_build b/source3/modules/wscript_build
index ff7163f..64de293 100644
--- a/source3/modules/wscript_build
+++ b/source3/modules/wscript_build
@@ -50,6 +50,7 @@ VFS_SCANNEDONLY_SRC = 'vfs_scannedonly.c'
 VFS_CROSSRENAME_SRC = 'vfs_crossrename.c'
 VFS_LINUX_XFS_SGID_SRC = 'vfs_linux_xfs_sgid.c'
 VFS_TIME_AUDIT_SRC = 'vfs_time_audit.c'
+VFS_CEPH_SRC = 'vfs_ceph.c'
 
 
 bld.SAMBA3_SUBSYSTEM('NFS4_ACLS',
@@ -469,3 +470,12 @@ bld.SAMBA3_MODULE('perfcount_test',
                  init_function='',
                  internal_module=bld.SAMBA3_IS_STATIC_MODULE('perfcount_test'),
                  enabled=bld.SAMBA3_IS_ENABLED_MODULE('perfcount_test'))
+
+bld.SAMBA3_MODULE('vfs_ceph',
+                 subsystem='vfs',
+                 source=VFS_CEPH_SRC,
+                 deps='samba-util cephfs',
+                 init_function='',
+                 internal_module=bld.SAMBA3_IS_STATIC_MODULE('vfs_ceph'),
+                 enabled=bld.SAMBA3_IS_ENABLED_MODULE('vfs_ceph'),
+                 cflags='-D_FILE_OFFSET_BITS=64')
diff --git a/source3/wscript b/source3/wscript
index 1ea3559..50a6e18 100644
--- a/source3/wscript
+++ b/source3/wscript
@@ -1749,6 +1749,10 @@ main() {
     if conf.CHECK_HEADERS('gpfs_gpl.h'):
         conf.DEFINE('HAVE_GPFS', '1')
 
+    conf.env['CCFLAGS_CEPHFS'] = "-D_FILE_OFFSET_BITS=64"
+    if conf.CHECK_HEADERS('cephfs/libcephfs.h', False, False, 'cephfs') and conf.CHECK_LIB('cephfs'):
+        conf.DEFINE('HAVE_CEPH', '1')
+
     default_static_modules=TO_LIST('''pdb_smbpasswd pdb_tdbsam pdb_wbc_sam
                                       auth_sam auth_unix auth_winbind auth_wbc auth_server
                                       auth_domain auth_builtin vfs_default
@@ -1792,6 +1796,9 @@ main() {
     if conf.CONFIG_SET('HAVE_GPFS'):
 	default_shared_modules.extend(TO_LIST('vfs_gpfs vfs_gpfs_hsm_notify'))
 
+    if conf.CONFIG_SET("HAVE_CEPH"):
+        default_shared_modules.extend(TO_LIST('vfs_ceph'))
+
     explicit_shared_modules = TO_LIST(Options.options.shared_modules, delimiter=',')
     explicit_static_modules = TO_LIST(Options.options.static_modules, delimiter=',')
 
-- 
1.7.9.5

